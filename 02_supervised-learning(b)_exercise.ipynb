{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKXjV0eXpK18"
   },
   "source": [
    "# 결정트리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공통"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %config InlineBackend.figure_format = \"retina\"\n",
    "%config InlineBackend.figure_formats = [\"pdf\", \"svg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hide_input": false,
    "id": "FyNjH-_qpK2E",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mglearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "matplotlib.rc(\"font\", family=\"Malgun Gothic\")\n",
    "# matplotlib.rc(\"font\", family=\"AppleGothic\")\n",
    "# matplotlib.rc('font', family='NanumBarunGothic')\n",
    "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"image.cmap\"] = \"viridis\"\n",
    "plt.rcParams[\"image.interpolation\"] = \"none\"\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"legend.numpoints\"] = 1\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    prop_cycle=(\n",
    "        cycler(\"color\", mglearn.plot_helpers.cm_cycle.colors)\n",
    "        + cycler(\"linestyle\", [\"-\", \"-\", \"--\", (0, (3, 3)), (0, (1.5, 1.5))])\n",
    "    ),\n",
    ")\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제01. load_iris 데이터를 로드하고, 데이터를 탐색하세요.\n",
    "- 데이터셋의 특성과 타깃(target)의 개수를 확인하세요.\n",
    "- 각 특성의 기초 통계 정보를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타깃의 개수 : 150\n",
      "특성 : ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(f\"타깃의 개수 : {len(iris.target)}\")\n",
    "print(f\"특성 : {iris.feature_names}\")\n",
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제01-2. 데이터를 학습 데이터와 테스트 데이터로 나누세요.\n",
    "- 학습 데이터와 테스트 데이터의 크기를 출력하세요.\n",
    "    - 데이터 분할은 train_test_split 함수를 사용하세요.\n",
    "    - 학습 데이터와 테스트 데이터의 비율은 80:20으로 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 X의 크기 : 120\n",
      "테스트 데이터 X의 크기 : 30\n",
      "훈련 데이터 y의 크기 : 120\n",
      "테스트 데이터 y의 크기 : 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,  \n",
    "                                                    iris.target,  \n",
    "                                                    stratify=iris.target, \n",
    "                                                    test_size=0.2,     \n",
    "                                                    random_state=42)\n",
    "print(f\"훈련 데이터 X의 크기 : {len(X_train)}\")\n",
    "print(f\"테스트 데이터 X의 크기 : {len(X_test)}\")\n",
    "print(f\"훈련 데이터 y의 크기 : {len(y_train)}\")\n",
    "print(f\"테스트 데이터 y의 크기 : {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제01-3. DecisionTreeClassifier를 사용하여 모델을 생성하세요.\n",
    "- 학습 데이터를 사용하여 모델을 학습시키세요.\n",
    "- 학습 완료 후, 학습 데이터에 대한 정확도를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "print(f\"학습 정확도 : {dt.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제04. 학습된 모델을 사용하여 테스트 데이터를 예측하세요.\n",
    "- 테스트 데이터에 대한 정확도를 출력하세요.\n",
    "- classification_report를 사용하여 평가 결과를 상세히 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도 : 0.9333333333333333\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(f\"테스트 정확도 : {dt.score(X_test, y_test)}\")\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "print(\"분류 보고서:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제05. 학습된 결정 트리를 시각화하세요.\n",
    "- plot_tree 함수를 사용하여 결정 트리의 구조를 그리세요.\n",
    "- 트리 시각화를 통해 어떤 특성이 중요한지 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
